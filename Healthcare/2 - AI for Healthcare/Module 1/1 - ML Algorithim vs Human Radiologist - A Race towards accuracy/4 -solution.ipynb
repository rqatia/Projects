{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there are so many fewer cancer cases than benign cases, accuracy would _not_ be a good statistic to use. A human or an algorithm could label _all_ of the cancer cases as benign and still achieve an accuracy of over 80%. \n",
    "\n",
    "Higher levels of false negatives aren't great ever in clinical settings, but they have less of an impact on the patient if we _know_ that there will be a second reader (i.e. our algorithm reads an image first, and then the label is confirmed by a radiologist). This also would only be appropriate if there wasn't a time-sensitive aspect to making the diagnosis. It seems more acceptable to have a high level of false positives in a situation as we saw in the previous exercise, where our algorithm was being used to prioritize emergency reads, in which case we would want to be somewhat liberal. \n",
    "\n",
    "Changing the threshold on the algorithm performance changed the FP and FN rates, one at the expense of the other. \n",
    "\n",
    "The algorithm's true positive rate increased when using the same threshold and comparing it to the human instead of the perfect labeler. This means that without the _true_ ground truth of diagnoses in an image, we may never be able to 100% accurately assess our algorithm, and its results may be inflated based on the quality of the radiologist labels that we use in comparing our outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I then read the set of labels into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  perfect_labeler radiologist  algorithm\n",
       "0          cancer      cancer       0.99\n",
       "1          cancer      cancer       0.94\n",
       "2          cancer      cancer       0.73\n",
       "3          cancer      cancer       0.82\n",
       "4          cancer      cancer       0.98\n",
       "5          cancer      cancer       0.63"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>perfect_labeler</th>\n      <th>radiologist</th>\n      <th>algorithm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cancer</td>\n      <td>cancer</td>\n      <td>0.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cancer</td>\n      <td>cancer</td>\n      <td>0.94</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cancer</td>\n      <td>cancer</td>\n      <td>0.73</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cancer</td>\n      <td>cancer</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cancer</td>\n      <td>cancer</td>\n      <td>0.98</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>cancer</td>\n      <td>cancer</td>\n      <td>0.63</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "labels.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I first started with assessing the radiologist's performance based upon :\n",
    "* Assessing the _accuracy_ of the radiologist by just looking at the percent of cases that they correctly labeled\n",
    "* Next, I look at the true positive and true negative rates of the radiologist by generating a _confusion matrix_ \n",
    "    * A Confusion matrix is an N x N matrix used for evaluating the performance of a                 classification model, where N is the number of target classes. The matrix compares the         actual target values with those predicted by the machine learning model. ... The rows          represent the predicted values of the target variable\n",
    "\n",
    "        * For more info, see : https://www.youtube.com/watch?v=bgyN3RO2ICo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiologist_accuracy = sum(labels.perfect_labeler == labels.radiologist)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8993288590604027"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "radiologist_accuracy"
   ]
  },
  {
   "source": [
    "### A classification accuracy of 8.9 is a very high accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "confusion_matrix(labels.perfect_labeler.values,labels.radiologist.values,labels=[\"cancer\",\"benign\"])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 25,   4],\n",
       "       [ 11, 109]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Looking at the above you may be confused to what the output of line 7 ([7]) is. \n",
    "#### This is what you call a matrix in Data  Science\n",
    "#### Array = its a data structure \n",
    "#### you can have different dimension (1D, 2D, 3D, 4D ... just like space and time )\n",
    "#### More info about Arrays https://subscription.packtpub.com/bookbig_data_and_business_intelligence/9781838555078/6/ch06lvl1sec34/confusion-matrix\n",
    "\n",
    "\n",
    "     \n",
    "    ### Now let's look at the algorithm's performance compared to the perfect labeler:\n",
    "* Since the algorithm doesn't create a binary label, it instead returns a _probability_ of cancer, choose a probability cut-off to use for the algorithm's labeling of cancer vs. bening. _(Hint: 0.5 is a reasonable starting place) - Supervised Learning - Regression \n",
    "* Start with assessing _accuracy_ again here\n",
    "* Generate a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   perfect_labeler  radiologist  algorithm\n",
       "0                1            1       0.99\n",
       "1                1            1       0.94\n",
       "2                1            1       0.73\n",
       "3                1            1       0.82\n",
       "4                1            1       0.98"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>perfect_labeler</th>\n      <th>radiologist</th>\n      <th>algorithm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.94</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.73</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.98</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "## Here, I'm going to change my entire dataframe to 0's and 1's to make processing easier\n",
    "labels = labels.replace('cancer',1).replace('benign',0)\n",
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_thresh = (labels.algorithm > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 21,   8],\n",
       "       [  8, 112]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "confusion_matrix(labels.perfect_labeler.values,algorithm_thresh,labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_thresh = sum(labels.perfect_labeler == labels.radiologist)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8993288590604027"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "algorithm_thresh"
   ]
  },
  {
   "source": [
    "### You can see the Machines accuracy on detecting the accurate diagnosis is also 0.8 or 0.9 rounded ( at cut off of 0.5)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens now if you change the threshold cut-off for your algorithm's classification to 0.4? What if you raise it to 0.6? How do accuracy, fp, fn, tp, and tn change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_thresh = (labels.algorithm > 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 25,   4],\n",
       "       [ 16, 104]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "confusion_matrix(labels.perfect_labeler.values,algorithm_thresh,labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_thresh = (labels.algorithm > 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 20,   9],\n",
       "       [  5, 115]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "confusion_matrix(labels.perfect_labeler.values,algorithm_thresh,labels=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's compare our algorithm to the radiologist\n",
    "* A \"perfect labeler\" might not exist in the real world, and in fact, if often does not\n",
    "* In AI for medical imaging, using a radiologist's labels as our \"true\" label is often the standard of practice, and algorithm performance is judged in both an academic setting as well as in the regulated industry landscape based on performance against an expert human\n",
    "\n",
    "* Repeat the steps above using a set threshold for your algorithm (again, 0.5 is perfectly reasonable) but now computing accuracy, tp, tn, fp, fn against the radiologist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_thresh = (labels.algorithm > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 23,  13],\n",
       "       [  6, 107]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "confusion_matrix(labels.radiologist.values,algorithm_thresh,labels=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEE Discussion.py to see the reflection of our studies and discussion on the results obtained.  \n",
    "\n",
    "# END OF DOCUMENT\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}